# Project Ideas

## 1. **Usability of AI-Generated Interfaces**

* **Research Question:** How do users perceive the usability of interfaces generated by AI tools compared to manually designed ones?
* **Method:** Take a simple task (e.g., a to-do list app). Show half the participants an AI-generated design (via Figma AI or Uizard) and the other half a human-made design. Run short usability tests.
* **Contribution:** Insights into trust, usability, and expectations of AI design tools.

---

## 2. **Dark Mode vs. Light Mode in Productivity Apps**

* **Research Question:** Does dark mode improve focus and reduce eye strain for short productivity tasks?
* **Method:** Have participants complete timed reading or form-filling tasks under light vs. dark mode. Collect performance and preference data.
* **Contribution:** Adds evidence to the ongoing debate about dark mode‚Äôs usability and health impact.

---

## 3. **Accessibility of Voice Assistants in Noisy Environments**

* **Research Question:** How effective are voice assistants (e.g., Siri, Google Assistant) in environments with varying background noise?
* **Method:** Simulate quiet vs. noisy environments (e.g., caf√© background noise) and measure success rates in task completion (setting reminders, searching info).
* **Contribution:** Practical insights for inclusive design in real-world conditions.

---

## 4. **Micro-Interactions and User Satisfaction**

* **Research Question:** Do small animations (e.g., button bounce, loading spinners) improve user satisfaction in mobile apps?
* **Method:** Create two versions of a small prototype app‚Äîone with micro-interactions, one without. Gather subjective ratings and measure engagement time.
* **Contribution:** Evidence on whether subtle design elements truly impact UX.

---

## 5. **Trust in Chatbots for Different Task Types**

* **Research Question:** Do users trust chatbots more for transactional tasks (e.g., booking tickets) than for advisory tasks (e.g., health tips)?
* **Method:** Present participants with chatbot interactions for both scenarios. Use surveys/interviews to capture perceived trust and reliability.
* **Contribution:** Helps design task-appropriate chatbot experiences.

---

## 6. **Gesture vs. Touch Controls in Mobile VR**

* **Research Question:** Which is more efficient and natural‚Äîgesture-based interaction or touchpad-based interaction in mobile VR?
* **Method:** Build or reuse a simple VR prototype (e.g., object selection). Compare time to complete tasks and subjective comfort.
* **Contribution:** Usability findings relevant to lightweight VR systems.

---

## 7. **Notifications and Task Interruption**

* **Research Question:** Do different types of mobile notifications (banner vs. silent vs. badge) affect task resumption time differently?
* **Method:** Have participants perform a typing or puzzle task while receiving different notification types. Measure task resumption time and frustration.
* **Contribution:** Guidance on designing less intrusive notification systems.

---

## 8. **Cultural Perceptions of Emojis in Communication**

* **Research Question:** Do people from different cultural backgrounds interpret common emojis (üòä, üôè, üëç) differently?
* **Method:** Short survey with participants from at least two cultural groups. Collect and compare interpretations.
* **Contribution:** Understanding emoji ambiguity in cross-cultural digital communication.

---

## 9. **AI Autocomplete and Writing Confidence**

* **Research Question:** Does AI-based autocomplete (like Gmail Smart Compose or ChatGPT inline assist) improve or reduce users‚Äô confidence in their own writing?
* **Method:** Ask participants to draft short emails or essays with and without autocomplete suggestions. Measure perceived confidence, editing time, and satisfaction through surveys.
* **Contribution:** Adds insight to current debates about over-reliance on AI in everyday writing tasks.


## 10. **Emotion Recognition in Video Calls**

* **Research Question:** Can simple visual cues (emoji reactions, sentiment meters) enhance empathy and communication in video calls?
* **Method:** Create two versions of a mock video-call interface: one standard, one showing basic real-time ‚Äúemotional feedback‚Äù (e.g., smile emoji if someone smiles). Run small group sessions and survey perceived connectedness.
* **Contribution:** Early evidence for affective computing features in remote collaboration tools.