# hci_lit_faisal

*Converted from PDF: hci_lit_faisal.pdf*

---

## Page 1

Literature Review: Response Time and Trust in AI Chatbots
Faisal Alzhrani
Student ID: g201829740
Course: Human–Computer Interaction
October 5, 2025
Research Question (RQ). How do instant (0–1 s) vs. delayed (1–3 s; 10 s) chatbot responses
affect users’ trust in the accuracy of the answer?
Introduction
Response time—the delay between a user’s message and a chatbot’s reply—is one of the most salient
cues users observe during text interaction. Prior work shows people treat timing as a social signal:
very fast replies can seem glib while very slow ones frustrate, yet findings in chatbot contexts are
mixed [6, 3, 4]. Understanding how timing shapes trust in accuracy is critical for high-stakes uses
(education, health, finance), where users must believe the content to act on it.
Proxy Paper
Zhang, Tsiakas, & Schneegass (CUI ’24)—“Explaining the Wait.” A between-subjects
online study (N=194) compared instant vs. dynamic delays and tested brief textual justifications.
Delay alone did not significantly change trust or social presence; justifications increased perceived
transparency and raised trust for instant responses (with minimal effect for dynamic delays) [9].
How we extend it: (a) test three delay bands (0–1 s, 1–3 s, ∼10 s); (b) measure trust in factual
accuracy directly (beyond social presence/satisfaction); (c) include moderators (age, prior chatbot
experience).
Thematic Summary
Theme 1:
How timing shapes trust & social presence.
An ECIS experiment reported
that dynamic delays (proportional to response complexity) increased perceived humanness/social
presence and overall satisfaction compared to near-instant replies [3]. A later BISE paper reconciled
inconsistencies: delays raised social presence but reduced usage intentions, with prior experience
moderating effects (novices read delays as human-like; experienced users preferred speed) [4]. A
foundational psychology result found a non-monotonic pattern for persuasion in timing: moderate
latency outperforms very short or very long latencies [6]. Outside pure chat, IP&M (2024) reports
an optimal ∼1–3 s communication delay for AI feedback tools (performance/engagement peak)
1

---

## Page 2

[7]. Individual differences matter: a BMC Psychology (2025) study found younger adults preferred
instant replies, whereas older adults preferred slower pacing (10–60 s) in companionship contexts
[8].
In e-commerce, higher interactivity (fast, responsive, capable) increased trust—here speed
operates as a competence signal [2].
Theme 2: Design moderators of the timing–trust link.
Typing indicators mitigate the
satisfaction drop from longer latency by increasing social presence [5]; earlier work shows indicators
boost social presence especially for novices [10]. Justifications (“I’m retrieving sources. . . ”) improve
perceived transparency and raise trust for instant responses [9]. Broader customer-service research
connects anthropomorphic cues and social presence with compliance [1]—relevant because delay
manipulations often work by shifting perceived humanness.
Research Gap
Most chatbot studies tie timing to social presence, satisfaction, or usage intentions; far fewer isolate
trust in factual accuracy. Delay ranges are often coarse (e.g., instant vs. dynamic) and moderators
(age, prior experience) are rarely modeled together.
We will experimentally manipulate three
delay bands (0–1 s, 1–3 s, ∼10 s), cross them with typing indicator vs. justification cues, and
measure accuracy-focused trust while modeling age and prior chatbot experience.
References
References
[1] Adam,
M.,
Wessel,
M.,
&
Benlian,
A.
(2020).
AI-based
chatbots
in
customer
service
and
their
effects
on
user
compliance.
Electronic
Markets,
31(2),
427–445.
https://doi.org/10.1007/s12525-020-00414-7
[2] Ding,
Y.,
& Najaf,
M. (2024). Interactivity,
humanness,
and trust:
A psycholog-
ical
approach
to
AI
chatbot
adoption
in
e-commerce.
BMC
Psychology,
12,
595.
https://doi.org/10.1186/s40359-024-02083-z
[3] Gnewuch, U., Morana, S., Adam, M. T. P., & Maedche, A. (2018). Faster is not always
better: Understanding the effect of dynamic response delays in human–chatbot interaction. In
Proceedings of ECIS 2018 (Portsmouth, UK). Available via AIS e Library.
[4] Gnewuch, U., Morana, S., Adam, M. T. P., & Maedche, A. (2022). Opposing effects of response
time in human–chatbot interaction: The moderating role of prior experience. Business &
Information Systems Engineering, 64(6), 773–791. https://doi.org/10.1007/s12599-022-00755-
x
[5] Kim, K., Shams, G., & Kim, K. (2025). From seconds to sentiments: Differential effects of
chatbot response latency on customer evaluations. International Journal of Human–Computer
Interaction, advance online publication.
[6] Moon, Y. (1999). The effects of physical distance and response latency on persuasion in
computer-mediated communication and human–computer interaction. Journal of Experimental
Psychology: Applied, 5(4), 379–392.
2

---

## Page 3

[7] Shi, Y., & Deng, B. (2024). Finding the sweet spot: Exploring the optimal communica-
tion delay for AI feedback tools. Information Processing & Management, 61(2), 103572.
https://doi.org/10.1016/j.ipm.2023.103572
[8] Wang, Y.-L., & Lo, C.-W. (2025). The effects of response time on older and young adults’ in-
teraction experience with chatbot. BMC Psychology, 13, 150. https://doi.org/10.1186/s40359-
025-02459-9
[9] Zhang, Z., Tsiakas, K., & Schneegass, C. (2024, July). Explaining the wait: How justifying
chatbot response delays impact user trust. In Proceedings of the ACM Conference on Conver-
sational User Interfaces (CUI ’24). https://doi.org/10.1145/3640794.3665550
[10] Gnewuch, U., Adam, M. T. P., Morana, S., & Maedche, A. (2018). “The chatbot is typing
. . . ” – The role of typing indicators in human–chatbot interaction. Pre-ICIS Workshop on HCI
Research in MIS (San Francisco, CA).
3

---
