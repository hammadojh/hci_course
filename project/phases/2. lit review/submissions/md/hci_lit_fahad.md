# hci_lit_fahad

*Converted from PDF: hci_lit_fahad.pdf*

---

## Page 1

Fahad Alzahrani 
G202421820 
SWE-503-01 
Literature Review 
Dr. Omar Hammad 
10. 05. 2025 
Do Explanations Matter? Proactive Communication and Trust in 
Fully Autonomous Taxis in Saudi Arabia 
Introduction 
Autonomous vehicles (AVs) are moving rapidly from concept to real-world pilot deployments. 
The rapid deployment of autonomous vehicle technologies, particularly robotaxis, offers 
numerous benefits such as improved mobility and traffic efficiency (Zhao, et al., 2025). There are 
current pilots of robotaxis in Saudi Arabia through collaborations with the Transport General 
Authority (TGA) and industry partners (e.g, , Uber, We Ride, and Ai Driver). Despite significant 
progress in perception, decision-making, and control technologies, public acceptance remains 
uncertain. A major obstacle is the trust gap: passengers may feel unsafe or anxious when vehicle 
behavior is opaque or unpredictable. This challenge is particularly acute in fully autonomous taxis 
(robotaxis), where there is no human driver to reassure passengers through explanations or visible 
intent. 
One promising design approach is proactive communication of driving intentions, a feature that 
enables, for example, announcing an upcoming lane change, stop, or reroute before the maneuver 
occurs. By making the system’s behavior transparent, proactive communication can enhance 
passengers’ sense of safety and confidence. However, it may also increase cognitive load if 
delivered excessively or at inappropriate moments. Therefore, careful study is required to 
determine whether proactive intent communication improves trust, safety perception, and 
willingness to use autonomous taxis. 
Problem Statement 
Although autonomous vehicles have reached a level of technical maturity sufficient for pilot 
operations, their widespread adoption hinges on human trust and perceived safety. Current systems 
often provide limited feedback, offering only status updates such as “turning” or “slowing down.” 
This minimalist style may leave passengers uncertain about what the vehicle is about to do, 
especially during complex maneuvers. Research indicates that proactive interaction, where the 
system communicates its intentions in advance, can potentially bridge this gap. 
This study addresses the problem of whether proactive communication of driving intentions in 
autonomous taxis in Saudi Arabia leads to higher levels of passenger trust, perceived safety, and 
willingness to use, compared to minimal communication.

---

## Page 2

Related Work 
The transition from human-controlled to autonomous driving requires rethinking how vehicles 
communicate with passengers. Existing studies highlight that trust plays a central role in the 
acceptance and proper use of automated systems. Building on this foundation, relevant previous 
work is examined in the subsequently through key themes that inform the present study. These 
thematic sections are: (1) the role of trust in technology use, (2) the evolution of human–vehicle 
interaction and the emergence of proactive communication, and (3) recent frameworks that 
conceptualize proactive interaction in autonomous vehicles. 
Trust and Technology 
Trust is central to the acceptance of automated systems, especially in safety-critical domains. 
Sheridan (2019) highlighted that correct use of modern technology depends strongly on trust, 
which shapes user reliance and willingness to delegate control. In the context of automation, trust 
also mitigates negative emotions and anxiety (Zhang et al., 2021), making it a crucial factor in 
passenger acceptance of autonomous mobility services. 
Trust lies at the heart of how people accept and use modern technological systems, particularly 
those that are critical and may influence safety and personal well-being. Sheridan (2019) noted the 
appropriate use of use of modern technology and advanced systems depends strongly on users’ 
trust and their confidence in them. This is essential in shaping both reliance and willingness to 
delegate control. From automated transportation to medical diagnosis, all recent developments 
across fields show that technology increasingly performs tasks once reserved for humans (Schuetz 
& Venkatesh, 2020; Schuetz et al., 2025). This expansion of machine capability has transformed 
how individuals live, work, and interact, making trust in technology a pervasive issue that affects 
nearly every domain of life (Schwab, 2016). 
There is a consensus which cofirms that humans’ trust in technology becomes a factor that enters 
virtually every domain. However, trust in technology operates as a double-edged concept. While 
modern systems can deliver remarkable efficiency and convenience, they may also introduce new 
categories of risk, such as misinformation, flawed recommendations, or biased decision-making. 
Consequently, maintaining an appropriate level of trust, neither over-trust nor under-trust, is 
essential to ensure safe and responsible use. In the context of autonomous transportation, 
cultivating well-calibrated trust is especially critical: passengers must feel assured that the 
vehicle’s decisions are reliable and transparent, yet remain attentive enough to intervene or 
disengage when necessary (Zhang et al., 2021). 
A study by Zhao, et al., (2025) investigated the challenges such new innocation may present for 
traffic management and law enforcement in China. The study explored how traffic law 
enforcement officers in Chinese cities with active robotaxi fleets perceive the introduction and 
operation of autonomous taxis. The research explored their views on safety, compliance, and daily 
management issues related to robotaxis, and used an online survey with more than 4,000 officers 
from major cities such as Beijing, Shanghai, and Shenzhen 
Findings indicate that most officers hold generally positive attitudes toward robotaxis, recognizing 
their potential to enhance road safety and improve traffic flow compared to conventional taxis. 
Nonetheless, many respondents expressed ongoing concerns about rule adherence, accident

---

## Page 3

liability, and cybersecurity risks. Statistical analysis showed that officers with greater exposure to 
automation technologies and previous experience with robotaxis were more likely to support their 
deployment. The study highlights the importance of frontline perspectives for shaping regulations 
and public policy on autonomous transport, emphasizing the need for continuous training, clear 
operational guidelines, and improved coordination between law enforcement and technology 
operators. 
Human–Vehicle Interaction and Proactive Communication 
As autonomous driving capabilities increase, the human role has shifted from direct control to 
supervisory oversight. Reviewing the literature from the past five years, a study by Sun et al. 
(2024) was found to be closely aligned with the scope of the present research in its purpose, 
methodology, and research questions. Sun et al. (2024) showed that proactive interaction (PI), 
which originated from sociological concept of proactive behavior, has measurable effects on trust 
in AVs. 
The study experimented in a controlled virtual reality environment using the Wizard-of-Oz method. 
It simulated three degrees of PI: low interaction (i.e., direct action without communication), 
medium interaction (i.e., informing the driver before action), and high interaction (i.e., seeking 
driver confirmation before action). The researchers found that higher levels of proactive 
communication generally increased trust, though effects varied by context, gender, and 
personality. In specific, communication style significantly affected perceived trust and system 
acceptance. When participants were not multitasking, higher levels of proactive communication 
increased their trust in the vehicle and improved perceptions of its capability. However, under 
multitasking conditions, drivers expressed greater trust in low-interaction systems, indicating that 
excessive or poorly timed communication could reduce comfort and confidence. 
Moreover, gender and personality traits moderated these effects. Female participants and 
moderately extroverted individuals tended to show higher trust in proactive systems, whereas male 
participants reported lower trust under medium interaction levels. Additionally, systems without 
PI were the least trusted when extroverted and less extroverted participants, which can be attributed 
to to situational awareness (Petersen, et al., 2019). The study concludes that trust in autonomous 
vehicles depends not only on technical reliability but also on how the system communicates with 
its users. It highlights the importance of adaptive interaction strategies that respond to contextual 
and personal factors—an insight particularly valuable for understanding how users in emerging 
robotaxi markets may develop or withhold trust toward self-driving vehicles. 
More recently, Chang, et al., (2025) investigates how pedestrian trust, receptivity, and behavior 
evolve during interactions with Level-4 AVs. The researchers conducted a real-world experiment 
in a commercial Robotaxi operation zone on 33 participants when they repeatedly crossed an 
uncontrolled intersection with frequent Level-4 Robotaxi traffic, and used behavior 
questionnaires and different other scales to meet their aims. Results showed pedestrians’ trust 
would increase after interacting with the Avs, and that personality factors can moderate the 
formation of trust in AVs. 
Similarly, Kraus et al. (2020) demonstrated that proactive dialogue strategies in automated 
assistants can significantly shape trust and user engagement. They classified the PI levels in robot

---

## Page 4

assistants from low to high as none, notification, suggestion, and intervention. The results indicated 
proactive dialogue showed strong effects on cognition-based trust (system's perceived competence 
and reliability) depending on task difficulty. 
Li et al. (2025) propose a framework for studying proactive interaction in automated vehicles. 
According to Li et al’s study, proactivity can be organized along multiple dimensions such as 
timing, modality, and informational content. Building on this framework, the present study focuses 
on proactive intent announcements, testing whether anticipatory communication improves 
passenger trust and perceived safety compared to minimal communication. 
Other existing research has investigated a similar aim of the effectiveness of proactive behavior 
but on social robots (e.g., Satake, 2009) or users’ perceptions of anthropomorphic attributes at five 
levels of proactive behavior in a social robot (e..g, Tan, et al., 2020). 
 
Gaps in Existing Research 
While studies confirm that proactive communication influences trust in AVs, most experiments 
have been conducted in driving simulators or VR settings with licensed drivers. Less is known 
about passengers in real or simulated robotaxis. Furthermore, to the best of my knowledge, the 
current research study will be the first to conducte in the context of Saudi Arabia, where 
autonomous mobility pilots are underway. Moreover, few studies explicitly test the balance 
between proactive intent announcements (transparent, anticipatory communication) versus 
minimal status updates (concise but opaque).

---

## Page 5

Reference: 
Chang, X., Yi, Z., Liu, Y., Sheng, H., & He, D. (2025). The Formation of Trust in Autonomous 
Vehicles after Interacting with Robotaxis on Public Roads. ar Xiv preprint ar Xiv:2510.00120. 
Chen, Y.; Shiwakoti, N.; Stasinopoulos, P.; Khan, S. K. (2022). State-of-the-Art of Factors 
Affecting the Adoption of Automated Vehicles. Sustainability, 14, 6697. 
Li, J., Currano, R., Miller, D. B., & Sirkin, D. (2025). A Framework for Proactive Interaction in 
Automated Vehicles. International Journal of Human–Computer Interaction, 1–18. https://doi-
org.sdl.idm.oclc.org/10.1080/10447318.2025.2487719 
Petersen, L.; Robert, L.; Yang, X. J.; Tilbury, D. M. (2019). Situational Awareness, Driver’s Trust 
in Automated Driving Systems and Secondary Task Performance. ar Xiv, ar Xiv:1903.05251. 
Satake, S., Kanda, T., Glas, D. F., Imai, M., Ishiguro, H., & Hagita, N. (2009, March). How to 
approach humans? Strategies for social robots to initiate interaction. In Proceedings of the 4th 
ACM/IEEE international conference on Human robot interaction (pp. 109-116). 
Schuetz, S., Kuai, L., Lacity, M. C., & Steelman, Z. (2025). A qualitative systematic review of 
trust in technology. Journal of Information Technology, 40(1), 55-76. 
https://doi.org/10.1177/02683962241254392 
Schuetz S and Venkatesh V (2020) The rise of human machines: how cognitive computing systems 
challenge assumptions of user-system interaction. Journal of the Association for Information 
Systems 21(2): 460–482. https://doi.org/10.17705/1jais.00608 
Schwab K (2016) Why everyone must get ready for the 4th industrial revolution. Currency. 
Sheridan, T. B. (2019). Individual Differences in Attributes of Trust in Automation: Measurement 
and Application to System Design. Front. Psychol., 10, 1117. 
Sun, J., Huang, Y., Huang, X., Zhang, J., & Zhang, H. (2024). Effect of Proactive Interaction on 
Trust 
in 
Autonomous 
Vehicles. Sustainability, 16(8), 
3404. 
https://doi.org/10.3390/su16083404 
Tan, H., Zhao, Y., Li, S., Wang, W., Zhu, M., Hong, J., & Yuan, X. (2020). Relationship between 
social robot proactive behavior and the human perception of anthropomorphic 
attributes. Advanced Robotics, 34(20), 1324-1336. 
Yang, C., Bao, Y., & Zhang, Z. (2024). More autonomy, more proactive? The (in) congruence 
effects of autonomy on proactive behaviour. Management Decision, 62(5), 1560-1575. 
https://doi.org/10.1108/MD-05-2023-0867 
Zhang, S.; Meng, Z.; Chen, B.; Yang, X.; Zhao, X. (2021). Motivation, Social Emotion, and the 
Acceptance of Artificial Intelligence Virtual Assistants—Trust-Based Mediating Effects. Front. 
Psychol., 12, 728495. 
Zhao, D., Xu, N., & Liu, J. (2025). Robotaxis in China: Firsthand perspectives of traffic law 
enforcement officers from Chinese cities with operational fleets. Journal of Intelligent 
Transportation Systems, 1–24. https://doi.org/10.1080/15472450.2025.2497503

---
