# hci_lit_waleed

*Converted from PDF: hci_lit_waleed.pdf*

---

## Page 1

Gesture vs. Touch Controls in VR/AR applications 

Waleed Al-Amri G202421440 
October 6, 2025 

SWE 503: Literature Review of Final Project 
Dr. Omar Hammad

---

## Page 2

1. Introduction 
 
Research Area and Importance 
In virtual and augmented reality (VR/AR) systems, interaction modalities such as gesture-
based and touch-based controls define the user's sense of immersion, efficiency, and comfort. As 
VR/AR technologies move toward more lightweight and mobile systems, identifying the most 
natural and efficient interaction mode becomes crucial. Gestures promise intuitive and contactless 
control that mimics real-world behavior, while touch interfaces provide familiarity, precision, and 
reduced fatigue. 
Specific Research Question 
This study explores: 
Which interaction mode—gesture-based or touchpad-based—is more efficient, natural, and 
usable in lightweight VR/AR systems? 
 
2. Proxy Paper 
Selected Paper 
Khundam, C. (2015). First Person Movement Control with Palm Normal and Hand Gesture 
Interaction in Virtual Reality. 
Summary of Study 
Khundam proposed a gesture-based system combining Oculus Rift (HMD) and Leap 
Motion sensors for first-person movement control in VR. The method allowed users to steer and 
adjust speed through real-time hand gestures using Unity3D. The study focused on immersive, 
continuous control rather than discrete button input, emphasizing user naturalness and system 
synchronization. 
Findings 
• 
Gesture-based control produced smoother, more immersive navigation compared to 
traditional keyboard input. 
• 
Users felt increased embodiment and realism when gestures replaced discrete key presses. 
• 
However, challenges included fatigue and tracking errors, particularly over long sessions 
or under lighting variations.

---

## Page 3

Relation to Current Research 
This study extends this foundation by comparing gesture-based and touchpad-based controls 
within both VR and AR contexts, assessing efficiency, user comfort, and usability across 
lightweight systems. While Khundam’s work explored immersion, the aims to quantify 
comparative performance and ergonomics in mobile or portable setups. 
 
3. Thematic Summary 
Theme 1: Gesture-Based Interaction – Naturalism and Limitations 
Gesture-based input is celebrated for its intuitiveness and immersive engagement. 
• 
Hürst & van Wezel (2012) evaluated finger tracking for mobile AR and found it enhances 
engagement but sacrifices precision. Gesture input in mid-air was “fun and natural” but 
less accurate and slower than touch-based alternatives, especially in object manipulation. 
• 
Ibraheem & Khan (2012) reviewed gesture recognition technologies and noted that 
vision-based systems offer natural interaction but face technical issues like lighting, 
occlusion, and computational complexity, limiting consistent usability 
• 
Khundam (2015) demonstrated that gesture-based VR navigation increases immersion but 
requires precise calibration and causes fatigue in extended use 
Synthesis: 
Gesture control excels in naturalism and embodiment, vital for immersive environments, 
but it suffers from accuracy loss, physical strain, and hardware dependency. Lightweight 
VR/AR devices exacerbate these issues due to limited sensors and battery constraints. 
 
Theme 2: Touch and Smartphone-Based Control – Precision and Efficiency 
Touch interfaces, though less “natural,” consistently outperform gesture systems in accuracy, 
speed, and usability, especially in mobile AR and lightweight setups. 
• 
Knierim et al. (2021) introduced the Sm ARtphone Controller system, where smartphones 
serve as both input (touch) and output (visual) devices in AR. Their user study (n=24) 
revealed that touch input achieved significantly higher precision and lower task load than 
mid-air gestures. 
• 
Matulic et al. (2021) developed Phonetroller, integrating smartphone touch input in VR. 
They found that users with visual thumb feedback performed tasks faster and more 
accurately than those using pure gesture or hover controls. 
• 
Pirttikangas et al. (2008) compared touch, mobile phone, and gesture control for large-
screen browsing. Results showed that touch and mobile input were more precise and less 
error-prone than gesture, which excelled only in exploratory, large-distance interactions

---

## Page 4

Synthesis: 
Touch interaction remains superior in precision, task efficiency, and user comfort, particularly in 
portable or mobile AR systems. Its tactile feedback supports stable control without significant 
physical effort, aligning well with lightweight VR/AR designs where fatigue and sensor drift can 
undermine performance. 
 
4. Research Gap 
While numerous studies have evaluated gesture-only or touch-only interactions, few have directly 
compared both modalities under identical conditions especially within lightweight VR/AR systems 
that emphasize portability, low-cost sensors, and minimal hardware. 
Most gesture studies (e.g., Khundam 2015; Hürst & van Wezel 2012) focused on immersion and 
movement realism, while touch studies (e.g., Knierim 2021; Matulic 2021) emphasized precision. 
However, no unified evaluation yet contrasts gesture vs. touch across both efficiency and 
naturalness dimensions. 
Importance 
Filling this gap will provide actionable design insights for developers of next-generation portable 
VR/AR systems, informing trade-offs between immersive naturalism (gesture) and efficient 
control (touch) in future human–computer interfaces. 
 
5. References 
1. Khundam, C. (2015). First Person Movement Control with Palm Normal and Hand 
Gesture Interaction in Virtual Reality. 
2. Hürst, W., & van Wezel, C. (2012). Gesture-Based Interaction via Finger Tracking for 
Mobile Augmented Reality. 
3. Knierim, P., Hein, D., Schmidt, A., & Kosch, T. (2021). The Sm ARtphone Controller: 
Leveraging Smartphones as Input and Output Modality for Improved Interaction within 
Mobile AR Environments. 
4. Matulic, F., Ganeshan, A., Fujiwara, H., & Vogel, D. (2021). Phonetroller: Visual 
Representations of Fingers for Precise Touch Input with Mobile Phones in VR. 
5. Pirttikangas, S., Milara, I. S., & Riekki, J. (2008). Comparison of Touch, Mobile Phone, 
and Gesture-Based Controlling of Browser Applications on a Large Screen. 
6. Ibraheem, N. A., & Khan, R. Z. (2012). Survey on Various Gesture Recognition 
Technologies and Techniques.

---
