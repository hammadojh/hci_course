# hci_lit_ibtisam

*Converted from PDF: hci_lit_ibtisam.pdf*

---

## Page 1

AI Autocomplete and User Confidence in 
Email Writing 
Introduction 
AI writing assistants are now common in email platforms like Gmail and Outlook. These tools 
suggest words and phrases as you type, promising to make writing faster and easier. However, 
we don't fully understand how these suggestions affect users emotionally specifically, whether 
they make people more or less confident in what they write. This review examines existing 
research to understand what we know about AI autocomplete in writing contexts and identifies 
where my study can contribute. 
Research Question: Does AI autocomplete functionality affect users' confidence in 
their email message content? 
Proxy Paper: Gmail Smart Compose 
Chen et al. (2019) published a paper on Gmail's Smart Compose system. They built a neural 
language model that predicts what you might type next and offers suggestions in real time. The 
system was designed to reduce repetitive typing and help users write emails faster. Their paper 
focuses on the technical side and how they trained the AI model and deployed it to millions of 
Gmail users. 
The authors mention that the user acceptance rate was important for their design, but they don't 
investigate the user experience deeply. They measured technical performance like accuracy but 
didn't explore psychological questions: Do users feel confident in emails written with AI help? 
While Chen et al. focused on whether Smart Compose works effectively and efficiently, I will 
study how it affects users emotionally. I'll measure whether using autocomplete makes people 
more or less confident in their email content. I'll use surveys comparing writing with and 
without AI assistance..

---

## Page 2

Related Work 
Trust in AI Generated Content 
Recent research shows that trust in AI systems varies based on how well users understand them. 
Buçinca et al. (2021) found that people sometimes over rely on AI suggestions, even when 
they're wrong, because they trust machines over their own judgment. This "automation bias" 
raises questions about whether autocomplete undermines users' confidence in their own writing 
abilities. 
Liu and Chilton (2024) studied AI tools in communication and found an interesting tension: 
users appreciated the speed of AI assisted writing but worried about authenticity. Participants 
questioned whether AI enhanced messages truly reflected their voice or intentions. This directly 
relates to confidence if you're unsure whether an email sounds like "you" you may lack 
confidence in sending it. 
Autocomplete's Effect on Writing Behavior 
Thompson et al. (2024) conducted one of the few studies specifically testing Google Smart 
Compose. They had people write with and without the feature enabled and compared the results. 
Interestingly, they found that autocomplete didn't dramatically change writing length or 
structure emails looked similar either way. 
However, this study only measured observable writing characteristics, not how users felt. They 
didn't ask whether writers felt confident, authentic, or satisfied with their emails. This is the gap 
my research addresses. 
Research Gap 
Despite millions of people using AI autocomplete daily, we lack research on its psychological 
effects. We know the AI model works (Chen et al., 2019) and that it doesn't drastically change 
writing output (Thompson et al., 2024), but we don't know how it makes users feel about their 
own writing. 
This matters because confidence affects communication beyond just speed. If users doubt their 
AI assisted emails, they may experience anxiety about how recipients will perceive them. 
Alternatively, if autocomplete reduces uncertainty about grammar or phrasing, it might actually 
boost confidence. 
My study fills this gap by directly measuring confidence when writing emails with versus 
without AI autocomplete. This will help us understand whether these tools support or 
undermine users' sense of ownership over their communication.

---

## Page 3

References 
Chen, M. X., Lee, B. N., Bansal, G., Cao, Y., Zhang, S., Lu, J., ... & Krikun, M. (2019). Gmail 
Smart Compose: Real-time assisted writing. Proceedings of the 25th ACM SIGKDD 
International Conference on Knowledge Discovery & Data Mining, 2287-2295. 
 
Buçinca, Z., Malaya, M. B., & Gajos, K. Z. (2021). To trust or to think: Cognitive forcing 
functions can reduce overreliance on AI in AI-assisted decision-making. Proceedings of the 
ACM on Human-Computer Interaction, 5(CSCW1), 1-21. 

Liu, V., & Chilton, L. B. (2024). From text to self: Users' perception of AI-mediated 
communication tools on interpersonal communication and self. Proceedings of the 2024 CHI 
Conference on Human Factors in Computing Systems, Article 423, 1-19. 
 
Thompson, N., Bonner, C., et al. (2024). The unexpected effects of Google Smart Compose on 
open-ended writing tasks. HCI International 2024 - Late Breaking Papers, Lecture Notes in 
Computer Science, vol 14731, 473-486. 
 
Yin, M., Vaughan, J. W., & Wallach, H. (2019). Understanding the effect of accuracy on trust in 
machine learning models. Proceedings of the 2019 CHI Conference on Human Factors in 
Computing Systems, Paper 279, 1-12.

---
